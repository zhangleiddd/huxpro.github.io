---
layout:     post
title:      "机器学习-聚类-kmeans算法"
date:       2019-01-15 14:15:00
author:     "Zhanglei"
header-mask: 0.3
catalog:    true
tags:
  - 机器学习
---


# 聚类算法：9、 k-Means++
## 类型
k-means算法属于原型聚类的一种。
原型的意思是原来的类型。原型聚类的思想是需要先假定数据集原本有k个类型，然后利用这些算法将样本集中的样本添加到这k个类型中，通常会先确定k个类型的样本，然后通过迭代直至类型中样本确定不变化。
## 算法原理
使用原型向量来刻画聚类结构。（使用向量来确定样本属于哪个类型）
## 数学基础
1、向量之间的欧式距离计算：
d = ((x11-x21)^2+(x12-x22)^2)^1/2
2、向量簇中均值向量的计算：
在这里的均值向量就是向量簇中每一种类型的平均值。
## 算法思想
1、输入样本集数据，输入k
2、从样本集中随机选取k个值，作为初始的均值向量
3、样本集中每一个样本计算与三个均值向量的欧式距离，构成k个簇
4、算出每个簇中的均值向量，重复2、3、4，直到簇中类型不再变化
## 例子

## 简单代码实现python



## 优点：
1、解决聚类问题的经典算法，简单、快速

2、当处理大数据集时，该算法保持可伸缩性和高效率

3、当簇近似为高斯分布时，它的效果较好
## 缺点：
1、在簇的平均值可被定义的情况下才能使用，可能不适用于某些应用

2、必须先给出k（要生成簇的数目），而且对初值敏感，即对于不同的初值，可能会导致不同结果

3、不适合非凸形状的簇或者大小差别很大的簇

4、对噪声和孤立点敏感
## 提高
记k个簇中心分别为u1,u2,u3……uk,每个簇的样本数目为N1、N2……Nk。

使用平方误差做为误差函数，得：

将该函数做为目标函数，求解该函数的最小值。可以使用梯度下降法求，该函数为凸函数，驻点为：

可以看到，要想使损失函数最小，聚类中心要为各簇中样本点的平均值。由此可以看出，K-means算法在每次迭代更新时使用各簇中样本点的平均值为聚类中心是有道理的。

## 补充
1）什么是均值向量u：
随机变量的期望组成的向量称为期望向量或者均值向量。
2）期望E(x)：
什么是期望：数学期望，简称期望后者均值。
如何计算：试验中每次可能结果的概率乘以其结果的总和。
意义：反映随机变量平均取值的大小。
离散型随机变量的期望：
E(x) = xkpk的连续和
大数定律规定，随着重复次数接近无穷大，数值的算术平均值几乎肯定地收敛于期望值。
